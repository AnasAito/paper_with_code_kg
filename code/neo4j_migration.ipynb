{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db='pwcgraph'):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri=\"bolt://localhost:7687\", user=\"neo4j\", pwd=\"0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear the database\n",
    "conn.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Write Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paper\n",
    "conn.query('CREATE CONSTRAINT papers IF NOT EXISTS ON (p:Paper)     ASSERT p.id IS UNIQUE')\n",
    "# author \n",
    "conn.query('CREATE CONSTRAINT authors IF NOT EXISTS ON (a:Author)     ASSERT a.id IS UNIQUE')\n",
    "# task \n",
    "conn.query('CREATE CONSTRAINT tasks IF NOT EXISTS ON (t:Task)         ASSERT t.id IS UNIQUE')\n",
    "# evaluation\n",
    "conn.query('CREATE CONSTRAINT evaluations IF NOT EXISTS ON (e:Evaluation) ASSERT e.id IS UNIQUE')\n",
    "# dataset\n",
    "conn.query('CREATE CONSTRAINT datasets IF NOT EXISTS ON (d:Dataset)     ASSERT d.id IS UNIQUE')\n",
    "# code \n",
    "conn.query('CREATE CONSTRAINT codes IF NOT EXISTS ON (c:Code)         ASSERT c.id IS UNIQUE')\n",
    "# method \n",
    "conn.query('CREATE CONSTRAINT methods IF NOT EXISTS ON (m:Method)     ASSERT m.id IS UNIQUE')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load nodes from ../data?knowledge_graph/\n",
    "papers = pd.read_csv(\"../data/knowledge_graph/papers_nodes.csv\")\n",
    "authors = pd.read_csv(\"../data/knowledge_graph/authors_nodes.csv\")\n",
    "tasks = pd.read_csv(\"../data/knowledge_graph/tasks_nodes.csv\")\n",
    "evaluations = pd.read_csv(\"../data/knowledge_graph/evaluations_nodes.csv\")\n",
    "datasets = pd.read_csv(\"../data/knowledge_graph/datasets_nodes.csv\")\n",
    "codes = pd.read_csv(\"../data/knowledge_graph/codes_nodes.csv\")\n",
    "methods = pd.read_csv(\"../data/knowledge_graph/methods_nodes.csv\")\n",
    "\n",
    "# drop duplicates preserving the first occurrence\n",
    "papers = papers.drop_duplicates(subset=['id'], keep='first')\n",
    "authors = authors.drop_duplicates(subset=['id'], keep='first')\n",
    "tasks = tasks.drop_duplicates(subset=['id'], keep='first')\n",
    "evaluations = evaluations.drop_duplicates(subset=['id'], keep='first')\n",
    "datasets = datasets.drop_duplicates(subset=['id'], keep='first')\n",
    "codes = codes.drop_duplicates(subset=['id'], keep='first')\n",
    "methods = methods.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "# remove rows with null id or Nan (should not happen)\n",
    "papers = papers.dropna(subset=['id'])\n",
    "authors = authors.dropna(subset=['id'])\n",
    "tasks = tasks.dropna(subset=['id'])\n",
    "evaluations = evaluations.dropna(subset=['id'])\n",
    "datasets = datasets.dropna(subset=['id'])\n",
    "codes = codes.dropna(subset=['id'])\n",
    "methods = methods.dropna(subset=['id'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record total=2877>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = tasks[['id','name',]]\n",
    "\n",
    "def add_tasks(tasks):\n",
    "    # Adds task nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (c:Task {id: row.id, name: row.name})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    return conn.query(query, parameters = {'rows':tasks.to_dict('records')})\n",
    "\n",
    "# write \n",
    "add_tasks(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# add papers\n",
    "attrs = ['id', 'title', 'abstract', 'year', 'url', 'pwc_id', 'label',]\n",
    "papers = papers[attrs]\n",
    "\n",
    "def add_papers(papers):\n",
    "    # Adds paper nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (p:Paper {id: row.id, title: row.title, year: row.year, url: row.url, pwc_id: row.pwc_id})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':papers.to_dict('records')})\n",
    "\n",
    "# write  \n",
    "# divide into batches \n",
    "papers_batches = np.array_split(papers, 100)\n",
    "for batch in papers_batches:\n",
    "    add_papers(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"Papers added:\", len(batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'id', 'label', 'source'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add authors \n",
    "attrs = ['id', 'name',]\n",
    "authors = authors[attrs]\n",
    "\n",
    "def add_authors(authors):\n",
    "    # Adds author nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (a:Author {id: row.id, name: row.name})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':authors.to_dict('records')})\n",
    "\n",
    "# write \n",
    "# divide into batches\n",
    "authors_batches = np.array_split(authors, 100)\n",
    "for batch in authors_batches:\n",
    "    add_authors(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"Authors added:\", len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record total=1948>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add methods\n",
    "attrs = ['id', 'name',]\n",
    "methods = methods[attrs]\n",
    "\n",
    "def add_methods(methods):\n",
    "    # Adds method nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (m:Method {id: row.id, name: row.name})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':methods.to_dict('records')})\n",
    "\n",
    "# write\n",
    "add_methods(methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record total=3611>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add datasets\n",
    "attrs = ['id', 'name',]\n",
    "datasets = datasets[attrs]\n",
    "\n",
    "def add_datasets(datasets):\n",
    "    # Adds dataset nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (d:Dataset {id: row.id, name: row.name})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':datasets.to_dict('records')})\n",
    "\n",
    "# write \n",
    "add_datasets(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "evaluations['metrics'] = evaluations['metrics'].apply(lambda x : ast.literal_eval(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations['metrics_key'] = evaluations['metrics'].apply(lambda x : list(x.keys()))\n",
    "evaluations['metrics_value'] = evaluations['metrics'].apply(lambda x : list(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key (x):\n",
    "    try : \n",
    "        return x[0]\n",
    "    except :\n",
    "        return None\n",
    "def extract_value (x):\n",
    "    try : \n",
    "        return x[0]\n",
    "    except :\n",
    "        return None\n",
    "evaluations['metric_key'] = evaluations['metrics_key'].apply(extract_key)\n",
    "evaluations['metric_value'] = evaluations['metrics_value'].apply(extract_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['id', 'metric_key', 'metric_value','model_name']\n",
    "evaluations = evaluations[attrs]\n",
    "\n",
    "def add_evaluations(evaluations):\n",
    "    # Adds evaluation nodes to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MERGE (e:Evaluation {id: row.id, metric_key: row.metric_key, metric_value: row.metric_value, model_name: row.model_name})\n",
    "            RETURN count(*) as total\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':evaluations.to_dict('records')})\n",
    "\n",
    "# write \n",
    "# divide into batches\n",
    "evaluations_batches = np.array_split(evaluations, 100)\n",
    "for batch in evaluations_batches:\n",
    "    add_evaluations(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"evaluations added:\", len(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(method) -> (paper)\n",
    "papers_methods = pd.read_csv('../data/knowledge_graph/method_paper.csv')\n",
    "\n",
    "\n",
    "\n",
    "def add_edges(papers_methods):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (p:Paper {id: row.target}), (m:Method {id: row.source})\n",
    "            CREATE (m)-[:FIRST_MENTIONED_IN]->(p)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':papers_methods.to_dict('records')})\n",
    "\n",
    "# WRITE \n",
    "add_edges(papers_methods)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (author) -> (paper)\n",
    "papers_authors = pd.read_csv('../data/knowledge_graph/authors_papers.csv')\n",
    "\n",
    "def add_edges(papers_authors):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (a:Author {id: row.source}), (p:Paper {id: row.target})\n",
    "            CREATE (a)-[:AUTHOR_OF]->(p)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':papers_authors.to_dict('records')})\n",
    "\n",
    "# write batches \n",
    "papers_authors_batches = np.array_split(papers_authors, 100)\n",
    "for batch in papers_authors_batches:\n",
    "    add_edges(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"edges added:\", len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (task) -> (paper)\n",
    "task_papers = pd.read_csv('../data/knowledge_graph/tasks_papers.csv')\n",
    "\n",
    "def add_edges(task_papers):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (d:Task {id: row.source}), (p:Paper {id: row.target})\n",
    "            CREATE (d)-[:BENCHMARKED_IN]->(p)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':task_papers.to_dict('records')})\n",
    "\n",
    "# write batches\n",
    "task_papers_batches = np.array_split(task_papers, 100)\n",
    "for batch in task_papers_batches:\n",
    "    add_edges(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"edges added:\", len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 313\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n",
      "edges added: 312\n"
     ]
    }
   ],
   "source": [
    "# (EVALUATION) -> (PAPER)\n",
    "evaluation_papers = pd.read_csv('../data/knowledge_graph/evals_papers.csv')\n",
    "\n",
    "def add_edges(evaluation_papers):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (e:Evaluation {id: row.source}), (p:Paper {id: row.target})\n",
    "            CREATE (e)-[:SUBMITED_BY]->(p)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':evaluation_papers.to_dict('records')})\n",
    "\n",
    "# write batches\n",
    "evaluation_papers_batches = np.array_split(evaluation_papers, 100)\n",
    "for batch in evaluation_papers_batches:\n",
    "        add_edges(batch)\n",
    "        time.sleep(1)\n",
    "        print(\"edges added:\", len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2078\n",
      "edges added: 2077\n",
      "edges added: 2077\n",
      "edges added: 2077\n",
      "edges added: 2077\n",
      "edges added: 2077\n"
     ]
    }
   ],
   "source": [
    "# (task) -> (eval)\n",
    "task_evaluations = pd.read_csv('../data/knowledge_graph/evals_tasks.csv')\n",
    "task_evaluations\n",
    "\n",
    "def add_edges(task_evaluations):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (d:Task {id: row.source}), (e:Evaluation {id: row.target})\n",
    "            CREATE (d)-[:SCORED_IN]->(e)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':task_evaluations.to_dict('records')})\n",
    "\n",
    "# WRITE BATCHES\n",
    "task_evaluations_batches = np.array_split(task_evaluations, 15)\n",
    "for batch in task_evaluations_batches:\n",
    "    add_edges(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"edges added:\", len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges added: 2082\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n",
      "edges added: 2081\n"
     ]
    }
   ],
   "source": [
    "# (dataset) -> (eval)\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "evals_datasets = pd.read_csv('../data/knowledge_graph/evals_datasets.csv')\n",
    "evals_datasets\n",
    "\n",
    "def add_edges(evals_datasets):\n",
    "    # Adds edges to the Neo4j graph.\n",
    "    query = '''\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (d:Dataset {id: row.source}), (e:Evaluation {id: row.target})\n",
    "            CREATE (d)-[:USED_IN]->(e)\n",
    "            '''\n",
    "    \n",
    "    return conn.query(query, parameters = {'rows':evals_datasets.to_dict('records')})\n",
    "\n",
    "# WRITE BATCHES\n",
    "dataset_evaluations_batches = np.array_split(evals_datasets, 15)\n",
    "for batch in dataset_evaluations_batches:\n",
    "    add_edges(batch)\n",
    "    time.sleep(1)\n",
    "    print(\"edges added:\", len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
