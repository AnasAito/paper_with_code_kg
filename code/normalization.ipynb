{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import json \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data \n",
    "# read 'papers-with-abstracts (1).json'\n",
    "\n",
    "with open('../data/raw/papers-with-abstracts (1).json', 'r') as f:\n",
    "    all_papers = json.load(f)\n",
    "\n",
    "# read evaluation-tables.json\n",
    "with open('../data/raw/evaluation-tables.json', 'r') as f:\n",
    "    evaluation_tables = json.load(f)\n",
    "    \n",
    "# read links-between-papers-and-code.json\n",
    "with open('../data/raw/links-between-papers-and-code.json', 'r') as f:\n",
    "    links = json.load(f)\n",
    "\n",
    "# read methods (1).json\n",
    "with open('../data/raw/methods (1).json', 'r') as f:\n",
    "    methods = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter papers with tasks\n",
    "def is_paper_valid(paper):\n",
    "    if paper['tasks']==[]:\n",
    "        return False\n",
    "    if paper['authors']==[]:\n",
    "        return False\n",
    "    return True\n",
    "all_papers = [paper for paper in all_papers if is_paper_valid(paper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform publish_date to datetime\n",
    "import datetime\n",
    "def intify(x):\n",
    "    try : \n",
    "        return int(x)\n",
    "    except:\n",
    "        return 0\n",
    "df['date_year'] = df['date'].apply(lambda x: intify(x.split('-')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_eval(eval_row):\n",
    "    nodes = []\n",
    "    # get task\n",
    "    task = eval_row['task']\n",
    "    for dataset in eval_row['datasets']:\n",
    "        dataset_name = dataset['dataset']\n",
    "        sotas = dataset['sota']['rows']\n",
    "        for sota in sotas:\n",
    "            paper_url = sota['paper_url']\n",
    "            model_name = sota['model_name']\n",
    "            metrics = sota['metrics']\n",
    "            node = {\n",
    "                'task': task,\n",
    "                'dataset': dataset_name,\n",
    "                'model_name': model_name,\n",
    "                'paper_url': paper_url,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            nodes.append(node)\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals =[]\n",
    "for eval_row in evaluation_tables:\n",
    "    nodes = get_paper_eval(eval_row)\n",
    "    evals.extend(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas dataframe\n",
    "df_eval = pd.DataFrame(evals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas dataframe\n",
    "df_links = pd.DataFrame(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to pandas dataframe\n",
    "df_methods = pd.DataFrame(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_eval.to_csv('../data/bronze/evaluation.csv', index=False)\n",
    "df_links.to_csv('../data/bronze/codes.csv', index=False)\n",
    "df_methods.to_csv('../data/bronze/methods.csv', index=False)\n",
    "df.to_csv('../data/bronze/papers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
